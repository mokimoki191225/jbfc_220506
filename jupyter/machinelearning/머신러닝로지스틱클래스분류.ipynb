{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13aa8582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "994a0256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# 머신러닝으로 업종별 매출액 예상하기?\n",
    "\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "# Training Data 2dim: x1(hours), x2(attendence)\n",
    "x_data = [[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]]  \n",
    "# Result Data : y(0:fail or 1:pass)\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]                     \n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b) # 아까 그 그래프가 sigmoid 이다.\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b11b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_2784\\367348450.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for step in tqdm_notebook(range(10001)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90bfd5dbfa54416bb3d4d226e3f337cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0 \t Cost : 0.7430492043495178\n",
      "Step : 1 \t Cost : 0.7321328520774841\n",
      "Step : 2 \t Cost : 0.72150057554245\n",
      "Step : 3 \t Cost : 0.7111538052558899\n",
      "Step : 4 \t Cost : 0.7010929584503174\n",
      "Step : 5 \t Cost : 0.6913184523582458\n",
      "Step : 6 \t Cost : 0.6818299889564514\n",
      "Step : 7 \t Cost : 0.6726274490356445\n",
      "Step : 8 \t Cost : 0.6637097001075745\n",
      "Step : 9 \t Cost : 0.6550756096839905\n",
      "Step : 200 \t Cost : 0.4218468964099884\n",
      "Step : 400 \t Cost : 0.3823147714138031\n",
      "Step : 600 \t Cost : 0.3591019809246063\n",
      "Step : 800 \t Cost : 0.3428586423397064\n",
      "Step : 1000 \t Cost : 0.33000972867012024\n",
      "Step : 1200 \t Cost : 0.31902754306793213\n",
      "Step : 1400 \t Cost : 0.3091982305049896\n",
      "Step : 1600 \t Cost : 0.3001621663570404\n",
      "Step : 1800 \t Cost : 0.29172614216804504\n",
      "Step : 2000 \t Cost : 0.28377869725227356\n",
      "Step : 2200 \t Cost : 0.2762506902217865\n",
      "Step : 2400 \t Cost : 0.26909589767456055\n",
      "Step : 2600 \t Cost : 0.26228079199790955\n",
      "Step : 2800 \t Cost : 0.25577929615974426\n",
      "Step : 3000 \t Cost : 0.24956989288330078\n",
      "Step : 3200 \t Cost : 0.2436339110136032\n",
      "Step : 3400 \t Cost : 0.2379549741744995\n",
      "Step : 3600 \t Cost : 0.23251797258853912\n",
      "Step : 3800 \t Cost : 0.22730910778045654\n",
      "Step : 4000 \t Cost : 0.2223156839609146\n",
      "Step : 4200 \t Cost : 0.21752572059631348\n",
      "Step : 4400 \t Cost : 0.21292807161808014\n",
      "Step : 4600 \t Cost : 0.208512544631958\n",
      "Step : 4800 \t Cost : 0.20426923036575317\n",
      "Step : 5000 \t Cost : 0.200189009308815\n",
      "Step : 5200 \t Cost : 0.196263387799263\n",
      "Step : 5400 \t Cost : 0.1924843192100525\n",
      "Step : 5600 \t Cost : 0.18884430825710297\n",
      "Step : 5800 \t Cost : 0.18533621728420258\n",
      "Step : 6000 \t Cost : 0.18195341527462006\n",
      "Step : 6200 \t Cost : 0.17868979275226593\n",
      "Step : 6400 \t Cost : 0.17553932964801788\n",
      "Step : 6600 \t Cost : 0.17249660193920135\n",
      "Step : 6800 \t Cost : 0.1695563793182373\n",
      "Step : 7000 \t Cost : 0.1667138934135437\n",
      "Step : 7200 \t Cost : 0.16396445035934448\n",
      "Step : 7400 \t Cost : 0.16130384802818298\n",
      "Step : 7600 \t Cost : 0.15872789919376373\n",
      "Step : 7800 \t Cost : 0.15623274445533752\n",
      "Step : 8000 \t Cost : 0.1538149118423462\n",
      "Step : 8200 \t Cost : 0.15147088468074799\n",
      "Step : 8400 \t Cost : 0.14919747412204742\n",
      "Step : 8600 \t Cost : 0.14699149131774902\n",
      "Step : 8800 \t Cost : 0.14485017955303192\n",
      "Step : 9000 \t Cost : 0.14277081191539764\n",
      "Step : 9200 \t Cost : 0.14075064659118652\n",
      "Step : 9400 \t Cost : 0.13878749310970306\n",
      "Step : 9600 \t Cost : 0.1368788629770279\n",
      "Step : 9800 \t Cost : 0.1350226253271103\n",
      "Step : 10000 \t Cost : 0.13321655988693237\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in tqdm_notebook(range(10001)):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 200 == 0 or step < 10 :\n",
    "            print(\"Step : {} \\t Cost : {}\".format(step, cost_val))\n",
    "            \n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced79ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Hypothesis: \n",
      "[[0.0242024 ]\n",
      " [0.1489122 ]\n",
      " [0.27185953]\n",
      " [0.79689527]\n",
      " [0.9489273 ]\n",
      " [0.9833507 ]] \n",
      "\n",
      "# Correct (Y): \n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "\n",
      "# Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"# Hypothesis: \\n{h} \\n\\n# Correct (Y): \\n{c} \\n\\n# Accuracy: {a}\".format(\n",
    "    h = h, c = c, a = a\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f64fc329",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ask score many\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOther scores \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Python\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:967\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    964\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 967\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[0;32m    970\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[1;32mC:\\Python\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1115\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;66;03m# Check session.\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed:\n\u001b[1;32m-> 1115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempted to use a closed Session.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1117\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe Session graph is empty. Add operations to the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1118\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph before calling run().\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "# Ask score many\n",
    "print(\"\\nOther scores \\t: \\n\", sess.run(hypothesis,\n",
    "                                        feed_dict={X : [10, 1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6464843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>-0.531170</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.145729</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>-0.766866</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.305514</td>\n",
       "      <td>-0.492741</td>\n",
       "      <td>-0.633333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.162444</td>\n",
       "      <td>-0.923997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>-0.344262</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.602837</td>\n",
       "      <td>0.284650</td>\n",
       "      <td>0.887276</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.411765</td>\n",
       "      <td>0.165829</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236960</td>\n",
       "      <td>-0.894962</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.647059</td>\n",
       "      <td>-0.216080</td>\n",
       "      <td>-0.180328</td>\n",
       "      <td>-0.353535</td>\n",
       "      <td>-0.791962</td>\n",
       "      <td>-0.076006</td>\n",
       "      <td>-0.854825</td>\n",
       "      <td>-0.833333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.155779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052161</td>\n",
       "      <td>-0.952178</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.764706</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.283688</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>-0.931682</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0.256281</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.868488</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.294118  0.487437  0.180328 -0.292929  0.000000  0.001490 -0.531170   \n",
       "1 -0.882353 -0.145729  0.081967 -0.414141  0.000000 -0.207153 -0.766866   \n",
       "2 -0.058824  0.839196  0.049180  0.000000  0.000000 -0.305514 -0.492741   \n",
       "3 -0.882353 -0.105528  0.081967 -0.535354 -0.777778 -0.162444 -0.923997   \n",
       "4  0.000000  0.376884 -0.344262 -0.292929 -0.602837  0.284650  0.887276   \n",
       "5 -0.411765  0.165829  0.213115  0.000000  0.000000 -0.236960 -0.894962   \n",
       "6 -0.647059 -0.216080 -0.180328 -0.353535 -0.791962 -0.076006 -0.854825   \n",
       "7  0.176471  0.155779  0.000000  0.000000  0.000000  0.052161 -0.952178   \n",
       "8 -0.764706  0.979899  0.147541 -0.090909  0.283688 -0.090909 -0.931682   \n",
       "9 -0.058824  0.256281  0.573770  0.000000  0.000000  0.000000 -0.868488   \n",
       "\n",
       "          7  8  \n",
       "0 -0.033333  0  \n",
       "1 -0.666667  1  \n",
       "2 -0.633333  0  \n",
       "3  0.000000  1  \n",
       "4 -0.600000  0  \n",
       "5 -0.700000  1  \n",
       "6 -0.833333  0  \n",
       "7 -0.733333  1  \n",
       "8  0.066667  0  \n",
       "9  0.100000  0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(\"./data/data-03-diabetes.csv\")\n",
    "df = pd.read_csv(\"./data/data-03-diabetes.csv\", header=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "204e9488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x_data.shape : (759, 8) \n",
      " y_data.shape : (759, 1)\n"
     ]
    }
   ],
   "source": [
    "# Lab 5 Logistic Regression Classifier\n",
    "# import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "xy = np.loadtxt('./data/data-03-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# print(x_data.shape, y_data.shape)\n",
    "print(\" x_data.shape : {x_shape} \\n y_data.shape : {y_shape}\".format(\n",
    "        x_shape = x_data.shape, \n",
    "        y_shape = y_data.shape\n",
    "    ))\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b) # 1,0으값 -> sigmoid\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) *\n",
    "                       tf.log(1 - hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db7a387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.294118  ,  0.487437  ,  0.180328  , -0.292929  ,  0.        ,\n",
       "         0.00149028, -0.53117   , -0.0333333 ,  0.        ],\n",
       "       [-0.882353  , -0.145729  ,  0.0819672 , -0.414141  ,  0.        ,\n",
       "        -0.207153  , -0.766866  , -0.666667  ,  1.        ],\n",
       "       [-0.0588235 ,  0.839196  ,  0.0491803 ,  0.        ,  0.        ,\n",
       "        -0.305514  , -0.492741  , -0.633333  ,  0.        ],\n",
       "       [-0.882353  , -0.105528  ,  0.0819672 , -0.535354  , -0.777778  ,\n",
       "        -0.162444  , -0.923997  ,  0.        ,  1.        ],\n",
       "       [ 0.        ,  0.376884  , -0.344262  , -0.292929  , -0.602837  ,\n",
       "         0.28465   ,  0.887276  , -0.6       ,  0.        ],\n",
       "       [-0.411765  ,  0.165829  ,  0.213115  ,  0.        ,  0.        ,\n",
       "        -0.23696   , -0.894962  , -0.7       ,  1.        ],\n",
       "       [-0.647059  , -0.21608   , -0.180328  , -0.353535  , -0.791962  ,\n",
       "        -0.0760059 , -0.854825  , -0.833333  ,  0.        ],\n",
       "       [ 0.176471  ,  0.155779  ,  0.        ,  0.        ,  0.        ,\n",
       "         0.052161  , -0.952178  , -0.733333  ,  1.        ],\n",
       "       [-0.764706  ,  0.979899  ,  0.147541  , -0.0909091 ,  0.283688  ,\n",
       "        -0.0909091 , -0.931682  ,  0.0666667 ,  0.        ],\n",
       "       [-0.0588235 ,  0.256281  ,  0.57377   ,  0.        ,  0.        ,\n",
       "         0.        , -0.868488  ,  0.1       ,  0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(xy)) \n",
    "xy[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "648509af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.294118  ,  0.487437  ,  0.180328  , -0.292929  ,  0.        ,\n",
       "         0.00149028, -0.53117   , -0.0333333 ],\n",
       "       [-0.882353  , -0.145729  ,  0.0819672 , -0.414141  ,  0.        ,\n",
       "        -0.207153  , -0.766866  , -0.666667  ],\n",
       "       [-0.0588235 ,  0.839196  ,  0.0491803 ,  0.        ,  0.        ,\n",
       "        -0.305514  , -0.492741  , -0.633333  ],\n",
       "       [-0.882353  , -0.105528  ,  0.0819672 , -0.535354  , -0.777778  ,\n",
       "        -0.162444  , -0.923997  ,  0.        ],\n",
       "       [ 0.        ,  0.376884  , -0.344262  , -0.292929  , -0.602837  ,\n",
       "         0.28465   ,  0.887276  , -0.6       ],\n",
       "       [-0.411765  ,  0.165829  ,  0.213115  ,  0.        ,  0.        ,\n",
       "        -0.23696   , -0.894962  , -0.7       ],\n",
       "       [-0.647059  , -0.21608   , -0.180328  , -0.353535  , -0.791962  ,\n",
       "        -0.0760059 , -0.854825  , -0.833333  ],\n",
       "       [ 0.176471  ,  0.155779  ,  0.        ,  0.        ,  0.        ,\n",
       "         0.052161  , -0.952178  , -0.733333  ],\n",
       "       [-0.764706  ,  0.979899  ,  0.147541  , -0.0909091 ,  0.283688  ,\n",
       "        -0.0909091 , -0.931682  ,  0.0666667 ],\n",
       "       [-0.0588235 ,  0.256281  ,  0.57377   ,  0.        ,  0.        ,\n",
       "         0.        , -0.868488  ,  0.1       ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x_data)) \n",
    "x_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e6a1b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(y_data)) \n",
    "y_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21e4924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_2784\\1152247385.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for step in tqdm_notebook(range(20001)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff155bb31f144b449e19270177f4f2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0 \t Cost : 1.0378105640411377\n",
      "Step : 1 \t Cost : 1.0360039472579956\n",
      "Step : 2 \t Cost : 1.0342001914978027\n",
      "Step : 3 \t Cost : 1.0323994159698486\n",
      "Step : 4 \t Cost : 1.0306012630462646\n",
      "Step : 5 \t Cost : 1.028806209564209\n",
      "Step : 6 \t Cost : 1.0270142555236816\n",
      "Step : 7 \t Cost : 1.0252249240875244\n",
      "Step : 8 \t Cost : 1.023438811302185\n",
      "Step : 9 \t Cost : 1.0216553211212158\n",
      "Step : 200 \t Cost : 0.7447590827941895\n",
      "Step : 400 \t Cost : 0.600660502910614\n",
      "Step : 600 \t Cost : 0.5523813962936401\n",
      "Step : 800 \t Cost : 0.5376949906349182\n",
      "Step : 1000 \t Cost : 0.5314603447914124\n",
      "Step : 1200 \t Cost : 0.527259886264801\n",
      "Step : 1400 \t Cost : 0.5237146019935608\n",
      "Step : 1600 \t Cost : 0.5205262303352356\n",
      "Step : 1800 \t Cost : 0.5176125764846802\n",
      "Step : 2000 \t Cost : 0.5149363875389099\n",
      "Step : 2200 \t Cost : 0.5124714374542236\n",
      "Step : 2400 \t Cost : 0.5101962685585022\n",
      "Step : 2600 \t Cost : 0.5080920457839966\n",
      "Step : 2800 \t Cost : 0.5061423182487488\n",
      "Step : 3000 \t Cost : 0.5043325424194336\n",
      "Step : 3200 \t Cost : 0.50264972448349\n",
      "Step : 3400 \t Cost : 0.5010824799537659\n",
      "Step : 3600 \t Cost : 0.4996207356452942\n",
      "Step : 3800 \t Cost : 0.49825519323349\n",
      "Step : 4000 \t Cost : 0.49697786569595337\n",
      "Step : 4200 \t Cost : 0.49578139185905457\n",
      "Step : 4400 \t Cost : 0.4946592152118683\n",
      "Step : 4600 \t Cost : 0.49360543489456177\n",
      "Step : 4800 \t Cost : 0.49261474609375\n",
      "Step : 5000 \t Cost : 0.4916823208332062\n",
      "Step : 5200 \t Cost : 0.4908038079738617\n",
      "Step : 5400 \t Cost : 0.4899752736091614\n",
      "Step : 5600 \t Cost : 0.4891930818557739\n",
      "Step : 5800 \t Cost : 0.4884539842605591\n",
      "Step : 6000 \t Cost : 0.4877549409866333\n",
      "Step : 6200 \t Cost : 0.4870932400226593\n",
      "Step : 6400 \t Cost : 0.4864664077758789\n",
      "Step : 6600 \t Cost : 0.48587217926979065\n",
      "Step : 6800 \t Cost : 0.4853082299232483\n",
      "Step : 7000 \t Cost : 0.4847727417945862\n",
      "Step : 7200 \t Cost : 0.4842640161514282\n",
      "Step : 7400 \t Cost : 0.4837803840637207\n",
      "Step : 7600 \t Cost : 0.4833201467990875\n",
      "Step : 7800 \t Cost : 0.482882022857666\n",
      "Step : 8000 \t Cost : 0.4824647307395935\n",
      "Step : 8200 \t Cost : 0.4820668697357178\n",
      "Step : 8400 \t Cost : 0.4816875159740448\n",
      "Step : 8600 \t Cost : 0.48132553696632385\n",
      "Step : 8800 \t Cost : 0.48097994923591614\n",
      "Step : 9000 \t Cost : 0.48064985871315\n",
      "Step : 9200 \t Cost : 0.4803343713283539\n",
      "Step : 9400 \t Cost : 0.480032742023468\n",
      "Step : 9600 \t Cost : 0.47974419593811035\n",
      "Step : 9800 \t Cost : 0.47946807742118835\n",
      "Step : 10000 \t Cost : 0.4792037010192871\n",
      "Step : 10200 \t Cost : 0.4789503812789917\n",
      "Step : 10400 \t Cost : 0.47870779037475586\n",
      "Step : 10600 \t Cost : 0.4784751236438751\n",
      "Step : 10800 \t Cost : 0.47825199365615845\n",
      "Step : 11000 \t Cost : 0.47803795337677\n",
      "Step : 11200 \t Cost : 0.47783252596855164\n",
      "Step : 11400 \t Cost : 0.47763532400131226\n",
      "Step : 11600 \t Cost : 0.4774458110332489\n",
      "Step : 11800 \t Cost : 0.47726380825042725\n",
      "Step : 12000 \t Cost : 0.4770888090133667\n",
      "Step : 12200 \t Cost : 0.47692057490348816\n",
      "Step : 12400 \t Cost : 0.476758748292923\n",
      "Step : 12600 \t Cost : 0.47660306096076965\n",
      "Step : 12800 \t Cost : 0.4764532446861267\n",
      "Step : 13000 \t Cost : 0.47630903124809265\n",
      "Step : 13200 \t Cost : 0.4761701226234436\n",
      "Step : 13400 \t Cost : 0.4760362505912781\n",
      "Step : 13600 \t Cost : 0.4759073257446289\n",
      "Step : 13800 \t Cost : 0.4757830798625946\n",
      "Step : 14000 \t Cost : 0.4756631851196289\n",
      "Step : 14200 \t Cost : 0.47554755210876465\n",
      "Step : 14400 \t Cost : 0.47543609142303467\n",
      "Step : 14600 \t Cost : 0.4753284454345703\n",
      "Step : 14800 \t Cost : 0.47522464394569397\n",
      "Step : 15000 \t Cost : 0.4751242995262146\n",
      "Step : 15200 \t Cost : 0.4750274419784546\n",
      "Step : 15400 \t Cost : 0.474933922290802\n",
      "Step : 15600 \t Cost : 0.47484347224235535\n",
      "Step : 15800 \t Cost : 0.4747561812400818\n",
      "Step : 16000 \t Cost : 0.47467169165611267\n",
      "Step : 16200 \t Cost : 0.4745900332927704\n",
      "Step : 16400 \t Cost : 0.474511057138443\n",
      "Step : 16600 \t Cost : 0.47443464398384094\n",
      "Step : 16800 \t Cost : 0.47436070442199707\n",
      "Step : 17000 \t Cost : 0.4742891490459442\n",
      "Step : 17200 \t Cost : 0.4742199182510376\n",
      "Step : 17400 \t Cost : 0.4741527736186981\n",
      "Step : 17600 \t Cost : 0.47408783435821533\n",
      "Step : 17800 \t Cost : 0.4740249216556549\n",
      "Step : 18000 \t Cost : 0.47396397590637207\n",
      "Step : 18200 \t Cost : 0.47390490770339966\n",
      "Step : 18400 \t Cost : 0.4738476872444153\n",
      "Step : 18600 \t Cost : 0.473792165517807\n",
      "Step : 18800 \t Cost : 0.47373828291893005\n",
      "Step : 19000 \t Cost : 0.4736860990524292\n",
      "Step : 19200 \t Cost : 0.4736354351043701\n",
      "Step : 19400 \t Cost : 0.4735863208770752\n",
      "Step : 19600 \t Cost : 0.4735386371612549\n",
      "Step : 19800 \t Cost : 0.4734923243522644\n",
      "Step : 20000 \t Cost : 0.47344744205474854\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in tqdm_notebook(range(20001)):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X: x_data, Y: y_data})       \n",
    "        if step % 200 == 0 or step < 10 :\n",
    "            print(\"Step : {} \\t Cost : {}\".format(step, cost_val))    \n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4922715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Hypothesis: \n",
      "[[0.3568853 ]\n",
      " [0.94513816]\n",
      " [0.23751095]\n",
      " [0.9574887 ]\n",
      " [0.11800208]\n",
      " [0.8324478 ]\n",
      " [0.9549511 ]\n",
      " [0.5947919 ]\n",
      " [0.18776229]\n",
      " [0.5815853 ]\n",
      " [0.7338283 ]\n",
      " [0.12974496]\n",
      " [0.32954434]\n",
      " [0.15344585]\n",
      " [0.7983915 ]\n",
      " [0.4101635 ]\n",
      " [0.7948825 ]\n",
      " [0.8071473 ]\n",
      " [0.8221144 ]\n",
      " [0.58300954]] \n",
      "\n",
      "# Correct (Y): \n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "\n",
      "# Accuracy: 0.7707509994506836\n"
     ]
    }
   ],
   "source": [
    "print(\"# Hypothesis: \\n{h} \\n\\n# Correct (Y): \\n{c} \\n\\n# Accuracy: {a}\".format(\n",
    "    # h = h, c = c, a = a\n",
    "    h = h[:20], c = c[:20], a = a\n",
    ")) # 전문의가 진단했을때 75%로 이 모델은 거의 이렇게 나온다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
